{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Face Detection Training Notebook\n",
    "## Real vs Fake Face Classification using CNN\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for detecting real vs AI-generated faces.\n",
    "\n",
    "### Project Overview\n",
    "- **Goal**: Build a binary classifier to detect real vs fake faces\n",
    "- **Model**: Simple Convolutional Neural Network (CNN)\n",
    "- **Dataset**: ~200 images (50% real, 50% fake)\n",
    "- **Framework**: TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_PATH = 'dataset'\n",
    "MODEL_SAVE_PATH = 'models/face_detector_model.h5'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path, img_size):\n",
    "    \"\"\"\n",
    "    Load images from dataset folder\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array of images\n",
    "        y: numpy array of labels (1 for real, 0 for fake)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load real faces (label = 1)\n",
    "    real_path = os.path.join(dataset_path, 'real')\n",
    "    if os.path.exists(real_path):\n",
    "        print(f\"Loading real faces from {real_path}...\")\n",
    "        for img_name in os.listdir(real_path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(real_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    images.append(img)\n",
    "                    labels.append(1)  # Real = 1\n",
    "        print(f\"Loaded {sum(1 for l in labels if l == 1)} real faces\")\n",
    "    \n",
    "    # Load fake faces (label = 0)\n",
    "    fake_path = os.path.join(dataset_path, 'fake')\n",
    "    if os.path.exists(fake_path):\n",
    "        print(f\"Loading fake faces from {fake_path}...\")\n",
    "        for img_name in os.listdir(fake_path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(fake_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    images.append(img)\n",
    "                    labels.append(0)  # Fake = 0\n",
    "        print(f\"Loaded {sum(1 for l in labels if l == 0)} fake faces\")\n",
    "    \n",
    "    # Convert to numpy arrays and normalize\n",
    "    X = np.array(images, dtype='float32') / 255.0\n",
    "    y = np.array(labels, dtype='float32')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "X, y = load_dataset(DATASET_PATH, IMG_SIZE)\n",
    "\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"Total images: {len(X)}\")\n",
    "print(f\"Image shape: {X[0].shape}\")\n",
    "print(f\"Real faces: {np.sum(y == 1)}\")\n",
    "print(f\"Fake faces: {np.sum(y == 0)}\")\n",
    "print(f\"Class distribution: {np.bincount(y.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "def plot_samples(X, y, num_samples=8):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(0, len(X))\n",
    "        axes[i].imshow(X[idx])\n",
    "        label = 'REAL' if y[idx] == 1 else 'FAKE'\n",
    "        color = 'green' if y[idx] == 1 else 'red'\n",
    "        axes[i].set_title(f'{label}', color=color, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Dataset into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Dataset Split:\")\n",
    "print(f\"Training set: {len(X_train)} images\")\n",
    "print(f\"  - Real: {np.sum(y_train == 1)}\")\n",
    "print(f\"  - Fake: {np.sum(y_train == 0)}\")\n",
    "print(f\"\\nValidation set: {len(X_val)} images\")\n",
    "print(f\"  - Real: {np.sum(y_val == 1)}\")\n",
    "print(f\"  - Fake: {np.sum(y_val == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    Create a simple CNN model for binary classification\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and Dense Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output Layer (Binary Classification)\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_model(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', \n",
    "             keras.metrics.Precision(name='precision'),\n",
    "             keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nTotal Parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"- Early Stopping (patience=5)\")\n",
    "print(\"- Learning Rate Reduction (factor=0.5, patience=3)\")\n",
    "print(\"- Model Checkpoint (save best model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\\n\")\n",
    "val_loss, val_acc, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  Accuracy: {val_acc*100:.2f}%\")\n",
    "print(f\"  Precision: {val_precision*100:.2f}%\")\n",
    "print(f\"  Recall: {val_recall*100:.2f}%\")\n",
    "print(f\"  F1-Score: {2*(val_precision*val_recall)/(val_precision+val_recall)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "print(\"Training history saved as 'training_history.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fake', 'Real'], \n",
    "            yticklabels=['Fake', 'Real'])\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Predictions on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some predictions\n",
    "def plot_predictions(model, X_val, y_val, num_samples=8):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    indices = np.random.choice(len(X_val), num_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = X_val[idx]\n",
    "        true_label = int(y_val[idx])\n",
    "        \n",
    "        # Make prediction\n",
    "        pred_prob = model.predict(np.expand_dims(img, axis=0), verbose=0)[0][0]\n",
    "        pred_label = 1 if pred_prob > 0.5 else 0\n",
    "        \n",
    "        # Display image\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        # Create title\n",
    "        true_text = 'REAL' if true_label == 1 else 'FAKE'\n",
    "        pred_text = 'REAL' if pred_label == 1 else 'FAKE'\n",
    "        confidence = pred_prob if pred_label == 1 else (1 - pred_prob)\n",
    "        \n",
    "        title = f'True: {true_text}\\nPred: {pred_text} ({confidence*100:.1f}%)'\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        axes[i].set_title(title, color=color, fontsize=10, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"✅ Model saved to: {MODEL_SAVE_PATH}\")\n",
    "print(f\"\\nModel file size: {os.path.getsize(MODEL_SAVE_PATH) / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete! Next Steps:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. The trained model has been saved\")\n",
    "print(\"2. Run the Streamlit app: streamlit run app.py\")\n",
    "print(\"3. Upload face images to test the model\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✅ Loading and preprocessing face images\n",
    "2. ✅ Building a CNN model architecture\n",
    "3. ✅ Training the model with proper callbacks\n",
    "4. ✅ Evaluating model performance\n",
    "5. ✅ Visualizing results and predictions\n",
    "6. ✅ Saving the trained model for deployment\n",
    "\n",
    "The model is now ready to be used in the Streamlit application!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
